{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "dyD6_z7G1013"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Black Friday Purchase Prediction Pipeline\")\n",
        "\n",
        "train_path = \"train.csv\"\n",
        "test_path = \"test.csv\"\n",
        "sample_path = \"sample_submission.csv\"\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "sample = pd.read_csv(sample_path)\n",
        "\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test shape: {test.shape}\")\n",
        "print(f\"Sample submission shape: {sample.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMnIIkjW44YL",
        "outputId": "68ed909b-3aed-4822-8fbc-95fa121903e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Black Friday Purchase Prediction Pipeline...\n",
            "Train shape: (550068, 12)\n",
            "Test shape: (233599, 12)\n",
            "Sample submission shape: (233599, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train['is_train'] = 1\n",
        "test['is_train'] = 0\n",
        "test['Purchase'] = np.nan\n",
        "\n",
        "combined = pd.concat([train, test], ignore_index=True, sort=False)\n",
        "print(f\"Combined dataset shape: {combined.shape}\")\n",
        "\n",
        "combined.columns = [c.strip().lower() for c in combined.columns]\n",
        "\n",
        "print(f\"Columns: {list(combined.columns)}\")\n",
        "\n",
        "print(\"Handling missing values and data types\")\n",
        "\n",
        "if 'stay_in_current_city_years' in combined.columns:\n",
        "    combined['stay_in_current_city_years'] = combined['stay_in_current_city_years'].astype(str)\n",
        "    combined['stay_in_current_city_years'] = combined['stay_in_current_city_years'].replace('4+', '4')\n",
        "    combined['stay_in_current_city_years'] = combined['stay_in_current_city_years'].replace('nan', np.nan)\n",
        "    combined['stay_in_current_city_years'] = pd.to_numeric(combined['stay_in_current_city_years'], errors='coerce')\n",
        "\n",
        "\n",
        "    median_stay = combined['stay_in_current_city_years'].median()\n",
        "    combined['stay_in_current_city_years'].fillna(median_stay, inplace=True)\n",
        "    print(f\"Converted stay_in_current_city_years to numeric, filled with median: {median_stay}\")\n",
        "    categorical_cols = ['gender', 'age', 'city_category', 'marital_status']\n",
        "for col in categorical_cols:\n",
        "    if col in combined.columns and combined[col].isnull().sum() > 0:\n",
        "        mode_val = combined[col].mode()[0] if len(combined[col].mode()) > 0 else 'Unknown'\n",
        "        combined[col].fillna(mode_val, inplace=True)\n",
        "        print(f\"Filled {combined[col].isnull().sum()} missing values in {col}\")\n",
        "\n",
        "numeric_cols = ['product_category_1', 'product_category_2', 'product_category_3']\n",
        "for col in numeric_cols:\n",
        "    if col in combined.columns:\n",
        "        # Ensure column is numeric\n",
        "        combined[col] = pd.to_numeric(combined[col], errors='coerce')\n",
        "        if combined[col].isnull().sum() > 0:\n",
        "            median_val = combined[col].median()\n",
        "            combined[col].fillna(median_val, inplace=True)\n",
        "            print(f\"Filled missing values in {col} with median: {median_val}\")\n",
        "\n",
        "print(\"\\nCreating new features\")\n",
        "\n",
        "\n",
        "if combined['age'].dtype == 'object':\n",
        "    age_mapping = {\n",
        "        '0-17': 0, '18-25': 1, '26-35': 2, '36-45': 3,\n",
        "        '46-50': 4, '51-55': 5, '55+': 6\n",
        "    }\n",
        "    combined['age_numeric'] = combined['age'].map(age_mapping)\n",
        "    combined['age_numeric'].fillna(combined['age_numeric'].median(), inplace=True)\n",
        "\n",
        "if 'product_category_1' in combined.columns and 'product_category_2' in combined.columns:\n",
        "    combined['product_cat_interaction'] = (\n",
        "        combined['product_category_1'].astype(str) + '_' +\n",
        "        combined['product_category_2'].fillna(0).astype(str)\n",
        "    )\n",
        "\n",
        "if 'city_category' in combined.columns and 'gender' in combined.columns:\n",
        "    combined['city_gender'] = combined['city_category'].astype(str) + '_' + combined['gender'].astype(str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P7v3_iT5ZIj",
        "outputId": "b05b6493-79a5-4936-e662-85ff48b2687d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (783667, 14)\n",
            "Columns: ['user_id', 'product_id', 'gender', 'age', 'occupation', 'city_category', 'stay_in_current_city_years', 'marital_status', 'product_category_1', 'product_category_2', 'product_category_3', 'purchase', 'is_train', 'comb']\n",
            "Handling missing values and data types\n",
            "Converted stay_in_current_city_years to numeric, filled with median: 2.0\n",
            "Filled missing values in product_category_2 with median: 9.0\n",
            "Filled missing values in product_category_3 with median: 14.0\n",
            "\n",
            "Creating new features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_mask = combined['is_train'] == 1\n",
        "train_data = combined[train_mask].copy()"
      ],
      "metadata": {
        "id": "wLbuvy796WNB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if 'user_id' in combined.columns:\n",
        "    user_aggs = train_data.groupby('user_id')['purchase'].agg(['mean', 'sum', 'count', 'std']).reset_index()\n",
        "    user_aggs.columns = ['user_id', 'user_avg_purchase', 'user_total_purchase', 'user_purchase_count', 'user_purchase_std']\n",
        "    user_aggs['user_purchase_std'].fillna(0, inplace=True)\n",
        "    combined = combined.merge(user_aggs, on='user_id', how='left')"
      ],
      "metadata": {
        "id": "U5PA95ue6Zo8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'product_id' in combined.columns:\n",
        "    product_aggs = train_data.groupby('product_id')['purchase'].agg(['mean', 'count', 'std']).reset_index()\n",
        "    product_aggs.columns = ['product_id', 'product_avg_purchase', 'product_purchase_count', 'product_purchase_std']\n",
        "    product_aggs['product_purchase_std'].fillna(0, inplace=True)\n",
        "    combined = combined.merge(product_aggs, on='product_id', how='left')"
      ],
      "metadata": {
        "id": "L7JBwK3R6ed1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'product_category_1' in combined.columns:\n",
        "    cat_aggs = train_data.groupby('product_category_1')['purchase'].agg(['mean', 'count']).reset_index()\n",
        "    cat_aggs.columns = ['product_category_1', 'cat1_avg_purchase', 'cat1_purchase_count']\n",
        "    combined = combined.merge(cat_aggs, on='product_category_1', how='left')"
      ],
      "metadata": {
        "id": "645lZJ8O6jfB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Encoding categorical variables\")\n",
        "le_cols = ['gender', 'age', 'city_category', 'marital_status']\n",
        "if 'product_cat_interaction' in combined.columns:\n",
        "    le_cols.append('product_cat_interaction')\n",
        "if 'city_gender' in combined.columns:\n",
        "    le_cols.append('city_gender')\n",
        "\n",
        "label_encoders = {}\n",
        "for col in le_cols:\n",
        "    if col in combined.columns:\n",
        "        le = LabelEncoder()\n",
        "        combined[col + '_encoded'] = le.fit_transform(combined[col].astype(str))\n",
        "        label_encoders[col] = le\n",
        "        print(f\"Encoded {col}: {len(le.classes_)} unique values\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A1DmlLl6xDN",
        "outputId": "31fa47be-d6df-4e98-8d9c-29f6c5bffbc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding categorical variables\n",
            "Encoded gender: 2 unique values\n",
            "Encoded age: 7 unique values\n",
            "Encoded city_category: 3 unique values\n",
            "Encoded marital_status: 2 unique values\n",
            "Encoded product_cat_interaction: 103 unique values\n",
            "Encoded city_gender: 6 unique values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_fe = combined[combined['is_train'] == 1].copy()\n",
        "test_fe = combined[combined['is_train'] == 0].copy()\n",
        "\n",
        "print(f\"Processed train shape: {train_fe.shape}\")\n",
        "print(f\"Processed test shape: {test_fe.shape}\")\n",
        "\n",
        "features = []\n",
        "\n",
        "basic_features = ['gender_encoded', 'marital_status_encoded', 'stay_in_current_city_years']\n",
        "if 'age_numeric' in train_fe.columns:\n",
        "    basic_features.append('age_numeric')\n",
        "else:\n",
        "    basic_features.append('age_encoded')\n",
        "features.extend([f for f in basic_features if f in train_fe.columns])\n",
        "\n",
        "city_product_features = ['city_category_encoded', 'product_category_1', 'product_category_2', 'product_category_3']\n",
        "features.extend([f for f in city_product_features if f in train_fe.columns])\n",
        "interaction_features = ['product_cat_interaction_encoded', 'city_gender_encoded']\n",
        "features.extend([f for f in interaction_features if f in train_fe.columns])\n",
        "agg_features = [\n",
        "    'user_avg_purchase', 'user_total_purchase', 'user_purchase_count', 'user_purchase_std',\n",
        "    'product_avg_purchase', 'product_purchase_count', 'product_purchase_std',\n",
        "    'cat1_avg_purchase', 'cat1_purchase_count'\n",
        "]\n",
        "features.extend([f for f in agg_features if f in train_fe.columns])\n",
        "\n",
        "\n",
        "features = [f for f in features if f in train_fe.columns]\n",
        "print(f\"\\nSelected {len(features)} features for modeling:\")\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OjR8xF97Gx-",
        "outputId": "e9693a90-7154-44a2-8514-dece4f733f74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed train shape: (550068, 32)\n",
            "Processed test shape: (233599, 32)\n",
            "\n",
            "Selected 19 features for modeling:\n",
            "['gender_encoded', 'marital_status_encoded', 'stay_in_current_city_years', 'age_numeric', 'city_category_encoded', 'product_category_1', 'product_category_2', 'product_category_3', 'product_cat_interaction_encoded', 'city_gender_encoded', 'user_avg_purchase', 'user_total_purchase', 'user_purchase_count', 'user_purchase_std', 'product_avg_purchase', 'product_purchase_count', 'product_purchase_std', 'cat1_avg_purchase', 'cat1_purchase_count']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_fe[features].copy()\n",
        "y = train_fe['purchase'].copy()\n",
        "test_X = test_fe[features].copy()\n",
        "\n",
        "print(f\"\\nFeature matrix shapes:\")\n",
        "print(f\"X: {X.shape}\")\n",
        "print(f\"test_X: {test_X.shape}\")\n",
        "\n",
        "\n",
        "print(\"\\nFinal imputation check\")\n",
        "\n",
        "print(\"Checking data types in feature matrix\")\n",
        "print(X.dtypes.value_counts())\n",
        "\n",
        "missing_counts = X.isnull().sum()\n",
        "if missing_counts.sum() > 0:\n",
        "    print(f\"Missing values found: {missing_counts[missing_counts > 0]}\")\n",
        "\n",
        "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
        "categorical_features = X.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "if len(categorical_features) > 0:\n",
        "    print(f\"Found categorical features that need encoding: {list(categorical_features)}\")\n",
        "\n",
        "    for col in categorical_features:\n",
        "        if col in X.columns:\n",
        "            le = LabelEncoder()\n",
        "            X[col] = le.fit_transform(X[col].astype(str))\n",
        "            test_X[col] = le.transform(test_X[col].astype(str))\n",
        "\n",
        "\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_imputed = pd.DataFrame(imp.fit_transform(X), columns=X.columns, index=X.index)\n",
        "test_X_imputed = pd.DataFrame(imp.transform(test_X), columns=test_X.columns, index=test_X.index)\n",
        "\n",
        "print(\"Missing values after imputation:\")\n",
        "print(f\"Train: {X_imputed.isnull().sum().sum()}\")\n",
        "print(f\"Test: {test_X_imputed.isnull().sum().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "249Z6NE874TU",
        "outputId": "af19f562-ef3c-41ac-8278-9d04e0d03f59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature matrix shapes:\n",
            "X: (550068, 19)\n",
            "test_X: (233599, 19)\n",
            "\n",
            "Final imputation check\n",
            "Checking data types in feature matrix\n",
            "int64      10\n",
            "float64     9\n",
            "Name: count, dtype: int64\n",
            "Missing values after imputation:\n",
            "Train: 0\n",
            "Test: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR4T2tt5tN3V",
        "outputId": "daed34b7-ae4d-486a-e843-ebea9b5d890c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model with GroupKFold cross-validation\n",
            "Training fold 1/5...\n",
            "Fold 1 RMSE (log scale): 0.3295\n",
            "Training fold 2/5...\n",
            "Fold 2 RMSE (log scale): 0.3239\n",
            "Training fold 3/5...\n",
            "Fold 3 RMSE (log scale): 0.3222\n",
            "Training fold 4/5...\n",
            "Fold 4 RMSE (log scale): 0.3204\n",
            "Training fold 5/5...\n",
            "Fold 5 RMSE (log scale): 0.3184\n",
            "\n",
            "Cross-validation results:\n",
            "Mean RMSE (log scale): 0.3229 (+/- 0.0038)\n",
            "Out-of-fold RMSE (original scale): 2544.11\n",
            "\n",
            "Prediction statistics:\n",
            "Mean: $8974.14\n",
            "Median: $7614.27\n",
            "Std: $4216.62\n",
            "Min: $317.89\n",
            "Max: $23269.28\n",
            "\n",
            "Submission saved as 'submission.csv'\n",
            "Submission shape: (233599, 3)\n",
            "\n",
            "First few predictions:\n",
            "       Purchase  User_ID Product_ID\n",
            "0  16647.254568  1000004  P00128942\n",
            "1  11421.807103  1000009  P00113442\n",
            "2   6361.976128  1000010  P00288442\n",
            "3   2478.154160  1000010  P00145342\n",
            "4   2419.749506  1000011  P00053842\n",
            "5  11172.405951  1000013  P00350442\n",
            "6  11495.078875  1000013  P00155442\n",
            "7  10628.493658  1000013   P0094542\n",
            "8  12699.601351  1000015  P00161842\n",
            "9   5376.624223  1000022  P00067942\n",
            "\n",
            "==================================================\n",
            "PIPELINE COMPLETED SUCCESSFULLY!\n",
            "Final CV RMSE: 2544.11\n",
            "Ready for submission!\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"\\nTraining model with GroupKFold cross-validation\")\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "oof_predictions = np.zeros(len(X_imputed))\n",
        "test_predictions = np.zeros(len(test_X_imputed))\n",
        "\n",
        "cv_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_imputed, y, train_fe['user_id'])):\n",
        "    print(f\"Training fold {fold + 1}/5...\")\n",
        "\n",
        "\n",
        "    X_train_fold = X_imputed.iloc[train_idx]\n",
        "    X_val_fold = X_imputed.iloc[val_idx]\n",
        "    y_train_fold = y.iloc[train_idx]\n",
        "    y_val_fold = y.iloc[val_idx]\n",
        "\n",
        "\n",
        "    model = HistGradientBoostingRegressor(\n",
        "        max_iter=500,\n",
        "        learning_rate=0.08,\n",
        "        max_depth=8,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "\n",
        "    model.fit(X_train_fold, np.log1p(y_train_fold))\n",
        "\n",
        "    val_preds = model.predict(X_val_fold)\n",
        "    oof_predictions[val_idx] = val_preds\n",
        "\n",
        "    test_preds = model.predict(test_X_imputed)\n",
        "    test_predictions += test_preds / 5\n",
        "\n",
        "\n",
        "    fold_rmse = np.sqrt(mean_squared_error(np.log1p(y_val_fold), val_preds))\n",
        "    cv_scores.append(fold_rmse)\n",
        "    print(f\"Fold {fold + 1} RMSE (log scale): {fold_rmse:.4f}\")\n",
        "\n",
        "\n",
        "mean_cv_score = np.mean(cv_scores)\n",
        "std_cv_score = np.std(cv_scores)\n",
        "print(f\"\\nCross-validation results:\")\n",
        "print(f\"Mean RMSE (log scale): {mean_cv_score:.4f} (+/- {std_cv_score:.4f})\")\n",
        "\n",
        "\n",
        "oof_rmse_original = np.sqrt(mean_squared_error(y, np.expm1(oof_predictions)))\n",
        "print(f\"Out-of-fold RMSE (original scale): {oof_rmse_original:.2f}\")\n",
        "\n",
        "\n",
        "final_predictions = np.expm1(test_predictions)\n",
        "final_predictions = np.maximum(final_predictions, 0)\n",
        "\n",
        "print(f\"\\nPrediction statistics:\")\n",
        "print(f\"Mean: ${final_predictions.mean():.2f}\")\n",
        "print(f\"Median: ${np.median(final_predictions):.2f}\")\n",
        "print(f\"Std: ${final_predictions.std():.2f}\")\n",
        "print(f\"Min: ${final_predictions.min():.2f}\")\n",
        "print(f\"Max: ${final_predictions.max():.2f}\")\n",
        "\n",
        "\n",
        "submission = sample.copy()\n",
        "submission['Purchase'] = final_predictions\n",
        "\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(f\"\\nSubmission saved as 'submission.csv'\")\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(\"\\nFirst few predictions:\")\n",
        "print(submission.head(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"Final CV RMSE: {oof_rmse_original:.2f}\")\n",
        "print(\"Ready for submission!\")\n",
        "print(\"=\"*50)"
      ]
    }
  ]
}